---
title: "Data 607: Assignment 9"
output: html_document
date: "2024-11-04"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(jsonlite)
library(httr)
library(tidyverse)

api_key <- "SCbzgkvE2BUSqcw0eH2tdMgMF4fCESjz"
```

## Introduction

This week's assignment focuses on APIs - I choose from one New York Times APIs, specifically top stories in the US today. I used jsonlite to construct an interface in R to read in the JSON data, and transform it into an R dataframe after signing up for an API key.

```{r us}
#Removed API key from code

top_stories <- paste0("https://api.nytimes.com/svc/topstories/v2/us.json?api-key=", api_key)

top_stories <- GET(top_stories)

stories_text <- content(top_stories, as = "text", encoding = "UTF-8")

stories_df <-fromJSON(stories_text) %>% as.data.frame

stories_df$results.title

```


## Analysis 
Let's take a look at the "subsection" of US top stories and plot them to see what most of them are about. I also used REGEX to look for certain words in the article's abstract.

```{r analysis}
stories_us <- stories_df %>%
  select(results.subsection) %>%
     group_by(results.subsection) %>%
  summarise(count = n())

stories_us$results.subsection[stories_us$results.subsection == ""] <- NA

stories_us <- stories_us %>% drop_na()

ggplot(data=stories_us, aes(x=results.subsection, y=count)) +
  geom_bar(stat="identity", fill="darkgreen", position = "dodge")+
  ggtitle("Top Articles in the US Subsections") +
   ylab("Frequency") + xlab("Article Subsections")


str_subset(stories_df$results.abstract, pattern = "elect")

str_subset(stories_df$results.abstract, pattern = "policy")
```
## Conclusion

The dataframe I pulled from the NYT API has 24 observations and 24 variables. I took a quick look at the titles of the 24 current articles in the US, and found that most of the top stories were about the 2024 election or politics but most likely still the election. I also searched for some words in the article with certain words, to see how many articles have discuss these topics. In the future, I would look at how top us articles compare to world articles, or even look at other methods to read in JSON data and transform it into a dataframe.